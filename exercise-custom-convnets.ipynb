{"metadata":{"jupytext":{"formats":"md,ipynb"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [Computer Vision](https://www.kaggle.com/learn/computer-vision) course.  You can reference the tutorial at [this link](https://www.kaggle.com/ryanholbrook/custom-convnets).**\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"# Introduction #\n\nIn these exercises, you'll build a custom convnet with performance competitive to the VGG16 model from Lesson 1.\n\nGet started by running the code cell below.","metadata":{}},{"cell_type":"code","source":"# Setup feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.computer_vision.ex5 import *\n\n# Imports\nimport os, warnings\nimport matplotlib.pyplot as plt\nfrom matplotlib import gridspec\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\n\n# Reproducability\ndef set_seed(seed=31415):\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\nset_seed()\n\n# Set Matplotlib defaults\nplt.rc('figure', autolayout=True)\nplt.rc('axes', labelweight='bold', labelsize='large',\n       titleweight='bold', titlesize=18, titlepad=10)\nplt.rc('image', cmap='magma')\nwarnings.filterwarnings(\"ignore\") # to clean up output cells\n\n\n# Load training and validation sets\nds_train_ = image_dataset_from_directory(\n    '../input/car-or-truck/train',\n    labels='inferred',\n    label_mode='binary',\n    image_size=[128, 128],\n    interpolation='nearest',\n    batch_size=64,\n    shuffle=True,\n)\nds_valid_ = image_dataset_from_directory(\n    '../input/car-or-truck/valid',\n    labels='inferred',\n    label_mode='binary',\n    image_size=[128, 128],\n    interpolation='nearest',\n    batch_size=64,\n    shuffle=False,\n)\n\n# Data Pipeline\ndef convert_to_float(image, label):\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    return image, label\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nds_train = (\n    ds_train_\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)\nds_valid = (\n    ds_valid_\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-07T16:05:19.495329Z","iopub.execute_input":"2023-06-07T16:05:19.495880Z","iopub.status.idle":"2023-06-07T16:05:40.127497Z","shell.execute_reply.started":"2023-06-07T16:05:19.495838Z","shell.execute_reply":"2023-06-07T16:05:40.126439Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"name":"stdout","text":"Found 5117 files belonging to 2 classes.\nFound 5051 files belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Design a Convnet #\n\nLet's design a convolutional network with a block architecture like we saw in the tutorial. The model from the example had three blocks, each with a single convolutional layer. Its performance on the \"Car or Truck\" problem was okay, but far from what the pretrained VGG16 could achieve. It might be that our simple network lacks the ability to extract sufficiently complex features. We could try improving the model either by adding more blocks or by adding convolutions to the blocks we have.\n\nLet's go with the second approach. We'll keep the three block structure, but increase the number of `Conv2D` layer in the second block to two, and in the third block to three.\n\n<figure>\n<!-- <img src=\"./images/2-convmodel-2.png\" width=\"250\" alt=\"Diagram of a convolutional model.\"> -->\n<img src=\"https://storage.googleapis.com/kaggle-media/learn/images/Vko6nCK.png\" width=\"250\" alt=\"Diagram of a convolutional model.\">\n</figure>\n\n# 1) Define Model #\n\nGiven the diagram above, complete the model by defining the layers of the third block.","metadata":{}},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\n\nmodel = keras.Sequential([\n    # Block One\n    layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same',\n                  input_shape=[128, 128, 3]),\n    layers.MaxPool2D(),\n\n    # Block Two\n    layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(),\n\n    # Block Three\n    # YOUR CODE HERE\n    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(),\n\n    # Head\n    layers.Flatten(),\n    layers.Dense(6, activation='relu'),\n    layers.Dropout(0.2),\n    layers.Dense(1, activation='sigmoid'),\n])\n\n# Check your answer\nq_1.check()","metadata":{"lines_to_next_cell":0,"execution":{"iopub.status.busy":"2023-06-07T16:07:34.649664Z","iopub.execute_input":"2023-06-07T16:07:34.650303Z","iopub.status.idle":"2023-06-07T16:07:35.568847Z","shell.execute_reply.started":"2023-06-07T16:07:34.650251Z","shell.execute_reply":"2023-06-07T16:07:35.567907Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.3333333333333333, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"1_Q1\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\n#q_1.hint()\n#q_1.solution()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2) Compile #\n\nTo prepare for training, compile the model with an appropriate loss and accuracy metric for the \"Car or Truck\" dataset.","metadata":{}},{"cell_type":"code","source":"model.compile(\n    optimizer=tf.keras.optimizers.Adam(epsilon=0.01),\n    # YOUR CODE HERE: Add loss and metric\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy']\n)\n\n# Check your answer\nq_2.check()","metadata":{"lines_to_next_cell":0,"execution":{"iopub.status.busy":"2023-06-07T16:08:33.132635Z","iopub.execute_input":"2023-06-07T16:08:33.133034Z","iopub.status.idle":"2023-06-07T16:08:33.159869Z","shell.execute_reply.started":"2023-06-07T16:08:33.133004Z","shell.execute_reply":"2023-06-07T16:08:33.158807Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.3333333333333333, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"2_Q2\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"cell_type":"code","source":"model.compile(\n    optimizer=tf.keras.optimizers.Adam(epsilon=0.01),\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy'],\n)\nq_2.assert_check_passed()","metadata":{"lines_to_next_cell":0,"execution":{"iopub.status.busy":"2023-06-07T16:08:36.727493Z","iopub.execute_input":"2023-06-07T16:08:36.728083Z","iopub.status.idle":"2023-06-07T16:08:36.747325Z","shell.execute_reply.started":"2023-06-07T16:08:36.728051Z","shell.execute_reply":"2023-06-07T16:08:36.746283Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.3333333333333333, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"2_Q2\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\n#q_2.hint()\n#q_2.solution()","metadata":{"lines_to_next_cell":0},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally, let's test the performance of this new model. First run this cell to fit the model to the training set.","metadata":{}},{"cell_type":"code","source":"history = model.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=50,\n)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T16:08:40.634778Z","iopub.execute_input":"2023-06-07T16:08:40.635196Z","iopub.status.idle":"2023-06-07T16:12:26.383971Z","shell.execute_reply.started":"2023-06-07T16:08:40.635164Z","shell.execute_reply":"2023-06-07T16:12:26.382812Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Epoch 1/50\n80/80 [==============================] - 46s 434ms/step - loss: 0.6762 - binary_accuracy: 0.5777 - val_loss: 0.6648 - val_binary_accuracy: 0.5785\nEpoch 2/50\n80/80 [==============================] - 3s 41ms/step - loss: 0.6661 - binary_accuracy: 0.5787 - val_loss: 0.6592 - val_binary_accuracy: 0.5785\nEpoch 3/50\n80/80 [==============================] - 3s 41ms/step - loss: 0.6635 - binary_accuracy: 0.5787 - val_loss: 0.6552 - val_binary_accuracy: 0.5785\nEpoch 4/50\n80/80 [==============================] - 3s 42ms/step - loss: 0.6609 - binary_accuracy: 0.5787 - val_loss: 0.6564 - val_binary_accuracy: 0.5785\nEpoch 5/50\n80/80 [==============================] - 3s 43ms/step - loss: 0.6588 - binary_accuracy: 0.5763 - val_loss: 0.6506 - val_binary_accuracy: 0.5787\nEpoch 6/50\n80/80 [==============================] - 3s 42ms/step - loss: 0.6537 - binary_accuracy: 0.6111 - val_loss: 0.6444 - val_binary_accuracy: 0.6104\nEpoch 7/50\n80/80 [==============================] - 3s 42ms/step - loss: 0.6470 - binary_accuracy: 0.6205 - val_loss: 0.6418 - val_binary_accuracy: 0.6139\nEpoch 8/50\n80/80 [==============================] - 3s 41ms/step - loss: 0.6406 - binary_accuracy: 0.6308 - val_loss: 0.6317 - val_binary_accuracy: 0.6329\nEpoch 9/50\n80/80 [==============================] - 3s 41ms/step - loss: 0.6316 - binary_accuracy: 0.6447 - val_loss: 0.6221 - val_binary_accuracy: 0.6561\nEpoch 10/50\n80/80 [==============================] - 3s 42ms/step - loss: 0.6237 - binary_accuracy: 0.6582 - val_loss: 0.6280 - val_binary_accuracy: 0.6565\nEpoch 11/50\n80/80 [==============================] - 3s 41ms/step - loss: 0.6173 - binary_accuracy: 0.6654 - val_loss: 0.6189 - val_binary_accuracy: 0.6589\nEpoch 12/50\n80/80 [==============================] - 3s 42ms/step - loss: 0.6094 - binary_accuracy: 0.6674 - val_loss: 0.6005 - val_binary_accuracy: 0.6838\nEpoch 13/50\n80/80 [==============================] - 3s 42ms/step - loss: 0.5997 - binary_accuracy: 0.6897 - val_loss: 0.5906 - val_binary_accuracy: 0.6983\nEpoch 14/50\n80/80 [==============================] - 3s 43ms/step - loss: 0.5830 - binary_accuracy: 0.7031 - val_loss: 0.5663 - val_binary_accuracy: 0.7064\nEpoch 15/50\n80/80 [==============================] - 3s 42ms/step - loss: 0.5562 - binary_accuracy: 0.7205 - val_loss: 0.5512 - val_binary_accuracy: 0.7117\nEpoch 16/50\n80/80 [==============================] - 3s 42ms/step - loss: 0.5303 - binary_accuracy: 0.7372 - val_loss: 0.5210 - val_binary_accuracy: 0.7412\nEpoch 17/50\n80/80 [==============================] - 3s 41ms/step - loss: 0.5107 - binary_accuracy: 0.7504 - val_loss: 0.4982 - val_binary_accuracy: 0.7616\nEpoch 18/50\n80/80 [==============================] - 3s 41ms/step - loss: 0.4800 - binary_accuracy: 0.7704 - val_loss: 0.4793 - val_binary_accuracy: 0.7697\nEpoch 19/50\n80/80 [==============================] - 3s 42ms/step - loss: 0.4564 - binary_accuracy: 0.7868 - val_loss: 0.4918 - val_binary_accuracy: 0.7725\nEpoch 20/50\n80/80 [==============================] - 3s 41ms/step - loss: 0.4245 - binary_accuracy: 0.8057 - val_loss: 0.4850 - val_binary_accuracy: 0.7757\nEpoch 21/50\n80/80 [==============================] - 3s 42ms/step - loss: 0.3961 - binary_accuracy: 0.8243 - val_loss: 0.4626 - val_binary_accuracy: 0.7921\nEpoch 22/50\n80/80 [==============================] - 3s 42ms/step - loss: 0.3882 - binary_accuracy: 0.8224 - val_loss: 0.5311 - val_binary_accuracy: 0.7345\nEpoch 23/50\n80/80 [==============================] - 3s 43ms/step - loss: 0.3583 - binary_accuracy: 0.8390 - val_loss: 0.4505 - val_binary_accuracy: 0.7880\nEpoch 24/50\n80/80 [==============================] - 3s 42ms/step - loss: 0.3333 - binary_accuracy: 0.8517 - val_loss: 0.4741 - val_binary_accuracy: 0.7892\nEpoch 25/50\n80/80 [==============================] - 3s 43ms/step - loss: 0.3272 - binary_accuracy: 0.8491 - val_loss: 0.5533 - val_binary_accuracy: 0.7399\nEpoch 26/50\n80/80 [==============================] - 3s 42ms/step - loss: 0.3032 - binary_accuracy: 0.8591 - val_loss: 0.4895 - val_binary_accuracy: 0.7699\nEpoch 27/50\n80/80 [==============================] - 3s 42ms/step - loss: 0.2676 - binary_accuracy: 0.8753 - val_loss: 0.5059 - val_binary_accuracy: 0.7872\nEpoch 28/50\n80/80 [==============================] - 3s 43ms/step - loss: 0.2562 - binary_accuracy: 0.8814 - val_loss: 0.4969 - val_binary_accuracy: 0.8105\nEpoch 29/50\n80/80 [==============================] - 3s 42ms/step - loss: 0.2469 - binary_accuracy: 0.8847 - val_loss: 0.4752 - val_binary_accuracy: 0.8086\nEpoch 30/50\n80/80 [==============================] - 3s 42ms/step - loss: 0.2503 - binary_accuracy: 0.8904 - val_loss: 0.5405 - val_binary_accuracy: 0.8058\nEpoch 31/50\n80/80 [==============================] - 4s 48ms/step - loss: 0.2399 - binary_accuracy: 0.8861 - val_loss: 0.5000 - val_binary_accuracy: 0.8202\nEpoch 32/50\n80/80 [==============================] - 3s 43ms/step - loss: 0.2337 - binary_accuracy: 0.8958 - val_loss: 0.6800 - val_binary_accuracy: 0.7990\nEpoch 33/50\n80/80 [==============================] - 3s 42ms/step - loss: 0.2039 - binary_accuracy: 0.9093 - val_loss: 0.6077 - val_binary_accuracy: 0.8101\nEpoch 34/50\n80/80 [==============================] - 3s 43ms/step - loss: 0.1738 - binary_accuracy: 0.9250 - val_loss: 0.5853 - val_binary_accuracy: 0.8236\nEpoch 35/50\n80/80 [==============================] - 3s 42ms/step - loss: 0.1449 - binary_accuracy: 0.9382 - val_loss: 0.5844 - val_binary_accuracy: 0.8303\nEpoch 36/50\n80/80 [==============================] - 3s 42ms/step - loss: 0.1321 - binary_accuracy: 0.9416 - val_loss: 0.9334 - val_binary_accuracy: 0.8115\nEpoch 37/50\n80/80 [==============================] - 3s 43ms/step - loss: 0.1253 - binary_accuracy: 0.9461 - val_loss: 0.7383 - val_binary_accuracy: 0.8165\nEpoch 38/50\n80/80 [==============================] - 3s 43ms/step - loss: 0.1272 - binary_accuracy: 0.9433 - val_loss: 0.7034 - val_binary_accuracy: 0.8103\nEpoch 39/50\n80/80 [==============================] - 3s 42ms/step - loss: 0.1237 - binary_accuracy: 0.9472 - val_loss: 0.7692 - val_binary_accuracy: 0.8179\nEpoch 40/50\n80/80 [==============================] - 4s 45ms/step - loss: 0.1168 - binary_accuracy: 0.9492 - val_loss: 0.5229 - val_binary_accuracy: 0.8305\nEpoch 41/50\n80/80 [==============================] - 3s 42ms/step - loss: 0.1237 - binary_accuracy: 0.9474 - val_loss: 0.6475 - val_binary_accuracy: 0.8289\nEpoch 42/50\n80/80 [==============================] - 3s 42ms/step - loss: 0.1005 - binary_accuracy: 0.9597 - val_loss: 0.7695 - val_binary_accuracy: 0.8032\nEpoch 43/50\n80/80 [==============================] - 3s 42ms/step - loss: 0.0979 - binary_accuracy: 0.9617 - val_loss: 0.8098 - val_binary_accuracy: 0.7802\nEpoch 44/50\n80/80 [==============================] - 3s 42ms/step - loss: 0.1015 - binary_accuracy: 0.9568 - val_loss: 0.9273 - val_binary_accuracy: 0.7961\nEpoch 45/50\n80/80 [==============================] - 3s 42ms/step - loss: 0.0827 - binary_accuracy: 0.9640 - val_loss: 0.7815 - val_binary_accuracy: 0.8371\nEpoch 46/50\n80/80 [==============================] - 3s 43ms/step - loss: 0.0840 - binary_accuracy: 0.9674 - val_loss: 0.7180 - val_binary_accuracy: 0.8260\nEpoch 47/50\n80/80 [==============================] - 3s 42ms/step - loss: 0.0707 - binary_accuracy: 0.9709 - val_loss: 0.8243 - val_binary_accuracy: 0.8357\nEpoch 48/50\n80/80 [==============================] - 3s 42ms/step - loss: 0.0615 - binary_accuracy: 0.9777 - val_loss: 0.7795 - val_binary_accuracy: 0.8408\nEpoch 49/50\n80/80 [==============================] - 4s 44ms/step - loss: 0.0569 - binary_accuracy: 0.9771 - val_loss: 0.8253 - val_binary_accuracy: 0.8424\nEpoch 50/50\n80/80 [==============================] - 3s 42ms/step - loss: 0.0566 - binary_accuracy: 0.9760 - val_loss: 0.8422 - val_binary_accuracy: 0.8359\n","output_type":"stream"}]},{"cell_type":"markdown","source":"And now run the cell below to plot the loss and metric curves for this training run.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nhistory_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot()\nhistory_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3) Train the Model #\n\nHow would you interpret these training curves? Did this model improve upon the model from the tutorial?","metadata":{}},{"cell_type":"code","source":"# View the solution (Run this code cell to receive credit!)\nq_3.check()","metadata":{"lines_to_next_cell":0},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion #\n\nThese exercises showed you how to design a custom convolutional network to solve a specific classification problem. Though most models these days will be built on top of a pretrained base, it certain circumstances a smaller custom convnet might still be preferable -- such as with a smaller or unusual dataset or when computing resources are very limited. As you saw here, for certain problems they can perform just as well as a pretrained model.\n\n# Keep Going #\n\nContinue on to [**Lesson 6**](https://www.kaggle.com/ryanholbrook/data-augmentation), where you'll learn a widely-used technique that can give a boost to your training data: **data augmentation**.","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/computer-vision/discussion) to chat with other learners.*","metadata":{}}]}